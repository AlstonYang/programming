{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 初始準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND='tensorflow'\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND='tensorflow'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#keras dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#keras functions\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#keras utils function => one-hot encoding\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀入 MNIST 數據庫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的原始網頁。\n",
    "\n",
    "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 由 Keras 讀入 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training data is 60000, the size is 28*28\n",
      "The number of testing data is 10000, the size is 28*28\n"
     ]
    }
   ],
   "source": [
    "print('The number of training data is %d, the size is %d*%d'\n",
    "      %x_train.shape)\n",
    "\n",
    "print('The number of testing data is %d, the size is %d*%d'\n",
    "      %x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 輸入格式整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們現在要用 CNN 學手寫辨識。因為 CNN 模型的資料需要多一個 channel (通道數)，因此我們要用 reshape 調校一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test = x_test.reshape(10000,28,28,1)\n",
    "print(x_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了後面需要，我們先將數字 0 和 1 的資料分別抓出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12665\n",
      "2115\n"
     ]
    }
   ],
   "source": [
    "x_train_01 = x_train[y_train<=1]\n",
    "x_test_01 = x_test[y_test<=1]\n",
    "\n",
    "print(len(x_train_01))\n",
    "print(len(x_test_01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "並將 label 轉換成 one-hot encoding 的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12665\n",
      "2115\n"
     ]
    }
   ],
   "source": [
    "y_train_01 = y_train[y_train<=1]\n",
    "y_test_01 = y_test[y_test<=1]\n",
    "\n",
    "print(len(y_train_01))\n",
    "print(len(y_test_01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0].shape)\n",
    "print(y_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_01 = np_utils.to_categorical(y_train_01, 2)\n",
    "y_test_01 = np_utils.to_categorical(y_test_01, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_01[0].shape)\n",
    "print(y_train_01[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 回顧 CNN 圖形辨識模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "經典的 CNN 圖形辨識模型 LeNet-5 是一個由兩層卷積層加三層全連接層所建立的神經網路，而在第二單元時，我們建立的 CNN 模型設定如下：\n",
    "\n",
    "* 起始為 3 個 convolutional block  \n",
    "    * 每個 convolutional block 為 1 個 2D Convolution + ReLU + 1 個 2D MaxPooling\n",
    "    * 2D Convolution 的數量為 32, 64, 128\n",
    "    * 每個 2D Convolution 的 kernal_size 為 3 或 (3, 3)，padding 使用 same\n",
    "    * 每個 2D MaxPooling 的 pool_size 為 2 或 (2, 2)，padding 使用 same\n",
    "* 將輸出結果 Flatten 後，接著兩層全連接層，神經元個數分別為 200 和 10 (數字的類別總數)\n",
    "\n",
    "我們當時建立的，是一個具有三層卷積層加兩層全連接的神經網路，其實可以看成是 LeNet-5 的一種變形。\n",
    "\n",
    "根據本單元的內容，我們可以使用下列方式使用 Sequential 重新建構第二單元的 CNN 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               230600    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 325,282\n",
      "Trainable params: 325,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_layer = [Conv2D(32, (3,3), padding='same', input_shape=(28,28,1)),\n",
    "                 Activation('relu'),\n",
    "                 MaxPooling2D(pool_size=(2,2)),\n",
    "                \n",
    "              Conv2D(64, (3,3), padding='same'),\n",
    "                 Activation('relu'),\n",
    "                 MaxPooling2D(pool_size=(2,2)),\n",
    "                 \n",
    "              Conv2D(128, (3,3), padding='same'),\n",
    "                 Activation('relu'),\n",
    "                 MaxPooling2D(pool_size=(2,2))]\n",
    "\n",
    "fc_layer = [Flatten(),\n",
    "               Dense(200),\n",
    "               Activation('relu'),\n",
    "               Dense(10),\n",
    "               Activation('softmax')]\n",
    "\n",
    "model = Sequential(conv_layer + fc_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('handwriting_weights_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 保留前三層 convolutional layer 並進行轉移學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此，我們一樣將 MNIST 資料集將僅有 0, 1的部分取出來，我們希望透過轉移學習建立一個類似 LeNet-5 的 0, 1 圖形辨識模型。\n",
    "\n",
    "請將下列三個 None 的部分進行修改，以透過轉移學習建立新的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 200)               230600    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 402       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 323,674\n",
      "Trainable params: 323,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_fc_layer=[Flatten(),\n",
    "                 Dense(200),\n",
    "                 Activation('relu'),\n",
    "                 Dense(2),\n",
    "                 Activation('softmax')]\n",
    "\n",
    "model_0_to_1 = Sequential(conv_layer+new_fc_layer)\n",
    "model_0_to_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in conv_layer:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12665/12665 [==============================] - 4s 308us/step - loss: 0.0187 - accuracy: 0.9803\n",
      "Epoch 2/10\n",
      "12665/12665 [==============================] - 4s 296us/step - loss: 0.0018 - accuracy: 0.9979\n",
      "Epoch 3/10\n",
      "12665/12665 [==============================] - 4s 300us/step - loss: 6.8383e-04 - accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "12665/12665 [==============================] - 4s 297us/step - loss: 7.8272e-04 - accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "12665/12665 [==============================] - 4s 307us/step - loss: 7.3219e-04 - accuracy: 0.9991\n",
      "Epoch 6/10\n",
      "12665/12665 [==============================] - 4s 301us/step - loss: 4.2707e-04 - accuracy: 0.9995\n",
      "Epoch 7/10\n",
      "12665/12665 [==============================] - 4s 301us/step - loss: 2.0389e-04 - accuracy: 0.9998\n",
      "Epoch 8/10\n",
      "12665/12665 [==============================] - 4s 307us/step - loss: 3.8831e-04 - accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "12665/12665 [==============================] - 4s 298us/step - loss: 2.1291e-04 - accuracy: 0.9998\n",
      "Epoch 10/10\n",
      "12665/12665 [==============================] - 4s 299us/step - loss: 3.5245e-04 - accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63cfd4e90>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_to_1.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "model_0_to_1.fit(x_train_01,y_train_01, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2115/2115 [==============================] - 1s 331us/step\n"
     ]
    }
   ],
   "source": [
    "score = model_0_to_1.evaluate(x_test_01, y_test_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:0.000000, Accuracy rate:1.000000\n"
     ]
    }
   ],
   "source": [
    "print('MSE:%f, Accuracy rate:%f' %(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_0_to_1_json = model_0_to_1.to_json()\n",
    "open('cnn_model_0_to_1_transferLearning_json.json','w').write(cnn_model_0_to_1_json)\n",
    "\n",
    "model_0_to_1.save_weights('cnn_model_0_to_1_transferLearning_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
